{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3c40781-0d8a-4a3d-9dbf-7f711f0331d8",
   "metadata": {},
   "source": [
    "# TF-IDF vectorized output passed into Random Forest Regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a425b6f3-04b5-4dce-bca4-28ab3524accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "%run -i ./Model_Eval.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92a927ba-dfe0-4344-8b1a-74ffd6f5c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"../Training_Data/one_star_reviews_balanced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff2bc1a4-b9c9-4188-be6b-3a1a9b047485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = training_data.head(10000) # just testing it out to make it faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "750232d9-a763-479e-9809-0c2686f01a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>reviewer_avg_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it is very poor quality. The color looks like ...</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Poor quality Sticks and has excessive play loc...</td>\n",
       "      <td>2.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Was nice until they doubled the price I was ju...</td>\n",
       "      <td>2.222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  reviewer_avg_rating\n",
       "0  it is very poor quality. The color looks like ...             4.000000\n",
       "1  Poor quality Sticks and has excessive play loc...             2.777778\n",
       "2  Was nice until they doubled the price I was ju...             2.222222"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3985042-7640-42ee-a893-ba5a15b9c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = training_data['full_text']\n",
    "labels = training_data['reviewer_avg_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02aaa67e-55be-45ec-b934-88083e582c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2cdce1e-1dc8-4fd0-b21b-8524cf681403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    wn = nltk.WordNetLemmatizer()\n",
    "    stopword = nltk.corpus.stopwords.words('english')\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lower = [word.lower() for word in tokens]\n",
    "    no_stopwords = [word for word in lower if word not in stopword]\n",
    "    no_alpha = [word for word in no_stopwords if word.isalpha()]\n",
    "    lemm_text = [wn.lemmatize(word) for word in no_alpha]\n",
    "    clean_text = lemm_text\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "733cbe86-6eb8-4ae0-8746-772b4e69b63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(data,tfidf_vect_fit):\n",
    "    X_tfidf = tfidf_vect_fit.transform(data)\n",
    "    words = tfidf_vect_fit.get_feature_names()\n",
    "    X_tfidf_df = pd.DataFrame(X_tfidf.toarray())\n",
    "    X_tfidf_df.columns = words\n",
    "    return(X_tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c66c2f6-bcb2-4720-9fda-468e0ae68174",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer=clean, max_features=1000)\n",
    "\n",
    "tfidf_vect_fit=tfidf_vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab587b87-49e3-4fff-9217-c8d22fa4ab65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tychi/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/tychi/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_vect = vectorize(X_train, tfidf_vect_fit)\n",
    "X_test_vect = vectorize(X_test, tfidf_vect_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afef9e53-ec8e-41fd-b3c3-be7646ff6420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91694e52-606a-4128-8e09-dd06f00d8b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=30, random_state=0, n_jobs=16, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b5d78-f4da-4bbd-b98f-298273d4ff7f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n"
     ]
    }
   ],
   "source": [
    "history = regr.fit(X_train_vect, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262bf4e6-5e5e-472a-9300-302e63a2207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_regression_model(\n",
    "    regr,\n",
    "    None,\n",
    "    X_train_vect,\n",
    "    Y_train,\n",
    "    X_test_vect,\n",
    "    Y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056f0b85-83b7-4bb2-9b86-cd07a90df111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
