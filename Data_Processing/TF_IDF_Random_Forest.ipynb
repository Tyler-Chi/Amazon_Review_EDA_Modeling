{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be2dfd13-44af-47d2-a764-4bbb3a4f741b",
   "metadata": {},
   "source": [
    "# TF IDF Random Forest Model\n",
    "\n",
    "### Pass output of TF-IDF into Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2898cf-7ac9-4457-8341-e828f8c281a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b24413e-fac1-4628-a373-75bfef331f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"../Training_Data/one_star_reviews_balanced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "538bee20-db4a-49be-9a9a-1050a203c9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>reviewer_avg_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Broke after 2 months, just past the return dat...</td>\n",
       "      <td>1.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ew... This thing is a piece of junk. It is pla...</td>\n",
       "      <td>1.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One Star Could never get to work properly.</td>\n",
       "      <td>1.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  reviewer_avg_rating\n",
       "0  Broke after 2 months, just past the return dat...             1.714286\n",
       "1  Ew... This thing is a piece of junk. It is pla...             1.785714\n",
       "2         One Star Could never get to work properly.             1.400000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f78e162-f88e-4a58-939c-48b0bc0810f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = training_data['full_text'].values, training_data['reviewer_avg_rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d294f055-16b6-4734-94e3-aab4959f6bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x,y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50d1cc98-6c5a-43c3-9ab6-aca5c41e467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    wn = nltk.WordNetLemmatizer()\n",
    "    stopword = nltk.corpus.stopwords.words('english')\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lower = [word.lower() for word in tokens]\n",
    "    no_stopwords = [word for word in lower if word not in stopword]\n",
    "    no_alpha = [word for word in no_stopwords if word.isalpha()]\n",
    "    lemm_text = [wn.lemmatize(word) for word in no_alpha]\n",
    "    clean_text = lemm_text\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30fb4823-f544-4340-b9a7-0a1247b02554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(data,tfidf_vect_fit):\n",
    "    X_tfidf = tfidf_vect_fit.transform(data)\n",
    "    words = tfidf_vect_fit.get_feature_names()\n",
    "    X_tfidf_df = pd.DataFrame(X_tfidf.toarray())\n",
    "    X_tfidf_df.columns = words\n",
    "    return(X_tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cab24391-75a1-428f-963f-bc4cb2909b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer=clean, max_features=1000) # 1000 word maximum, otherwise this will be way too large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69429baa-5c37-430d-8c4c-4f53fe4732d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect_fit=tfidf_vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1092d43f-7257-48e3-b5dc-d92afd3c27f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tychi/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/tychi/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_vector = vectorize(X_train, tfidf_vect_fit)\n",
    "X_test_vector = vectorize(X_test, tfidf_vect_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04bd327-4205-4cc1-8da3-12ca871ce1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0, verbose=True)\n",
    "regressor.fit(X_train_vector, Y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fc7dac-11f5-4ca8-b809-e2d82a236eca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
